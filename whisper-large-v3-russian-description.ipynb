{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель whisper-large-v3-russian представляет собой дообученную модель whisper-large-v3 для русского языка.\n",
    "\n",
    "\n",
    "Модель дообучалась на открытом датасете mozilla-foundation/common_voice_17_0 [https://huggingface.co/datasets/mozilla-foundation/common_voice_17_0/viewer/ru] 200 тыс строк\n",
    "Размер словаря модели = 51866 токенов (уникальных слов)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Данные из файла config.json (содержит подробности о процессе дообучения)\n",
    "{\n",
    "  \"_name_or_path\": \"openai/whisper-large-v3\", # используется предобученная модель whisper-large-v3.\n",
    "  \"activation_dropout\": 0.0, # параметр для предотвращения переобучения, здесь не применяется.\n",
    "  \"activation_function\": \"gelu\", # GELU (Gaussian Error Linear Unit).\n",
    "  \"apply_spec_augment\": false, # метод \"SpecAugment\" для усиления данных не применяется.\n",
    "  \"architectures\": [           # используется модель для генерации WhisperForConditionalGeneration.\n",
    "    \"WhisperForConditionalGeneration\"\n",
    "  ],\n",
    "  \"attention_dropout\": 0.0,    # параметр для предотвращения переобучения на слое attention, здесь не применяется.\n",
    "  \"begin_suppress_tokens\": [\n",
    "    220,\n",
    "    50257\n",
    "  ],\n",
    "  \"bos_token_id\": 50257,\n",
    "  \"classifier_proj_size\": 256, # количество выходных признаков в скрытом слое.\n",
    "  \"d_model\": 1280,             # количество выходных нейронов слоя.\n",
    "  \"decoder_attention_heads\": 20, # определяет, сколько разных параметров внимания модель может учитывать одновременно в процессе декодирования.\n",
    "  \"decoder_ffn_dim\": 5120,     # размер полносвязного слоя (Feed Forward Network) в декодере. Это количество нейронов в этом слое.\n",
    "  \"decoder_layerdrop\": 0.0,    # вероятность дропаут-а для слоев декодера, не применяется.\n",
    "  \"decoder_layers\": 32,        # количество слоев в декодере. Это количество итераций, которые модель проведет для обработки входных данных.\n",
    "  \"decoder_start_token_id\": 50258, # начальный токен для последовательности.\n",
    "  \"dropout\": 0.0,              # общая вероятность дропаут для других слоев модели, не применяется.\n",
    "  \"encoder_attention_heads\": 20,   # количество замедлений/голов внимания в энкодере, аналогично декодеру.\n",
    "  \"encoder_ffn_dim\": 5120,     # размер полносвязного слоя в энкодере.\n",
    "  \"encoder_layerdrop\": 0.0,    # вероятность дропаут-а для слоев энкодера, не применяется.\n",
    "  \"encoder_layers\": 32,        # количество слоев в энкодере.\n",
    "  \"eos_token_id\": 50257,       # идентификатор токена конца последовательности (End Of Sequence). Этот токен указывает, когда завершать последовательность.\n",
    "  \"init_std\": 0.02,            # стандартное отклонение для инициализации весов модели.\n",
    "  \"is_encoder_decoder\": true,  # модель является энкодер-декодером.\n",
    "  \"mask_feature_length\": 10,   # длина маскируемых признаков = 10.\n",
    "  \"mask_feature_min_masks\": 0, # минимальное количество масок для применения к признакам.\n",
    "  \"mask_feature_prob\": 0.0,    # вероятность маскирования признаков, здесь не применяется (0%).\n",
    "  \"mask_time_length\": 10,      # длина маскируемого временного окна.\n",
    "  \"mask_time_min_masks\": 2,    # минимальное количество масок для применения ко времени.\n",
    "  \"mask_time_prob\": 0.05,      # вероятность маскирования временных данных.\n",
    "  \"max_length\": 448,           # максимальная длина выходной последовательности.\n",
    "  \"max_source_positions\": 1500, # максимальное количество позиций для входных данных.\n",
    "  \"max_target_positions\": 448,  # максимальное количество позиций для выходных данных.\n",
    "  \"median_filter_width\": 7,    # ширина медианного фильтра для обработки.\n",
    "  \"model_type\": \"whisper\",     # тип модели, в данном случае это Whisper.\n",
    "  \"num_hidden_layers\": 32,     # общее количество скрытых слоев в модели.\n",
    "  \"num_mel_bins\": 128,         # число мел-структур для обработки аудиоданных.\n",
    "  \"pad_token_id\": 50256,       # идентификатор токена заполнения (pad token), используется для выравнивания последовательностей.\n",
    "  \"scale_embedding\": false,    # параметр, определяющий, раскладывать ли векторные представления.\n",
    "  \"torch_dtype\": \"bfloat16\",   # тип данных, используемый в PyTorch (bfloat16).\n",
    "  \"transformers_version\": \"4.40.2\", # версия библиотеки Transformers, с которой была создана модель.\n",
    "  \"use_cache\": true,                # если true, модель будет кэшировать выходные данные для более быстрой обработки.\n",
    "  \"use_weighted_layer_sum\": false,  # если true, применяется взвешенная сумма выходных данных слоев, в данном случае это не так.\n",
    "  \"vocab_size\": 51866               # размер словаря модели (количество уникальных токенов).\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Данные из файла preprocessor_config.json\n",
    "{\n",
    "  \"chunk_length\": 30, # длина фрагмента (в секундах), на который будет разбито аудио. \n",
    "  \"feature_extractor_type\": \"WhisperFeatureExtractor\", # тип извлекателя признаков, используемого для обработки аудиоданных. Здесь Whisper.\n",
    "  \"feature_size\": 128,      # размерность извлекаемых признаков. Это количество характеристик, которые будут извлекаться из аудиосигнала. Чем выше размерность, тем больше информации может быть сохранено.\n",
    "  \"hop_length\": 160,        # размер шага (в числовом выражении), с которым перемещаются окна при разбиении аудио на фрагменты. \n",
    "  \"n_fft\": 400,             # размер окна для быстрого преобразования Фурье, используется 400 отсчетов.\n",
    "  \"n_samples\": 480000,      # указывает, сколько отсчетов (или выборок) аудио будет обработано в модели.\n",
    "  \"nb_max_frames\": 3000,    # максимальное количество кадров (или окон) признаков, которые модель может обрабатывать за один раз. Это ограничение помогает управлять объемом данных, передаваемых в модель, что также может предотвратить переполнение памяти.\n",
    "  \"padding_side\": \"right\",  # сторона, с которой будут добавляться нули (паддинг) к аудиоданным. Указание right означает, что паддинг будет добавлен в конец последовательности.\n",
    "  \"padding_value\": 0.0,     # бескачественные участки будут заполнены нулями.\n",
    "  \"processor_class\": \"WhisperProcessor\", # класс процессора, который будет использоваться для обработки аудиоданных\n",
    "  \"return_attention_mask\": false,        # не возвращать маску внимания вместе с извлекаемыми признаками. Маска внимания не нужна для текущей задачи.\n",
    "  \"sampling_rate\": 16000    # частота дискретизации аудиосигнала, измеряемая в Гц. В данном случае 16 кГц (16000 Гц) - стандратная для Whisper.\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
